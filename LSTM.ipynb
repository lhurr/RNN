{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Resizing, Rescaling, Reshape\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Input, InputLayer, Normalization, Flatten,BatchNormalization, Dropout\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "\n",
    "from kapre.time_frequency import Melspectrogram, Spectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "from tensorflow.keras.datasets.cifar10 import load_data\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets.cifar10 import load_data\n",
    "from tensorflow.keras.optimizers.schedules import *\n",
    "from tensorflow.keras.metrics import FalseNegatives, binary_crossentropy, binary_accuracy, categorical_crossentropy, sparse_categorical_crossentropy\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "import librosa\n",
    "from librosa import stft\n",
    "from librosa import display as dispwav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "# Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 13 03:39:45 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 462.59       Driver Version: 462.59       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce MX450      WDDM  | 00000000:58:00.0 Off |                  N/A |\n",
      "| N/A   46C    P8    N/A /  N/A |    119MiB /  2048MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12025564293726771292\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Speech commands dataset version 2 already exists. Skipping download.\n",
      "Converting test set WAVs to numpy files\n",
      "[]\n",
      "Converting training set WAVs to numpy files\n",
      "[]\n",
      "Done preparing Google Speech commands dataset version 2\n"
     ]
    }
   ],
   "source": [
    "from Speech import PrepareGoogleSpeechCmd\n",
    "gscInfo, nCategs = PrepareGoogleSpeechCmd(version=2, task='35word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = gscInfo['train']['files'], gscInfo['train']['labels']\n",
    "X_test, y_test = gscInfo['test']['files'], gscInfo['test']['labels']\n",
    "X_val, y_val = gscInfo['val']['files'], gscInfo['val']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_labels = {'unknown': 0,\n",
    "            'silence': 0,\n",
    "            '_unknown_': 0,\n",
    "            '_silence_': 0,\n",
    "            '_background_noise_': 0,\n",
    "            'yes': 2,\n",
    "            'no': 3,\n",
    "            'up': 4,\n",
    "            'down': 5,\n",
    "            'left': 6,\n",
    "            'right': 7,\n",
    "            'on': 8,\n",
    "            'off': 9,\n",
    "            'stop': 10,\n",
    "            'go': 11,\n",
    "            'zero': 12,\n",
    "            'one': 13,\n",
    "            'two': 14,\n",
    "            'three': 15,\n",
    "            'four': 16,\n",
    "            'five': 17,\n",
    "            'six': 18,\n",
    "            'seven': 19,\n",
    "            'eight': 20,\n",
    "            'nine': 1,\n",
    "            'backward': 21,\n",
    "            'bed': 22,\n",
    "            'bird': 23,\n",
    "            'cat': 24,\n",
    "            'dog': 25,\n",
    "            'follow': 26,\n",
    "            'forward': 27,\n",
    "            'happy': 28,\n",
    "            'house': 29,\n",
    "            'learn': 30,\n",
    "            'marvin': 31,\n",
    "            'sheila': 32,\n",
    "            'tree': 33,\n",
    "            'visual': 34,\n",
    "            'wow': 35}\n",
    "labels = dict((v,k) for k,v in raw_labels.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, list_IDs, labels, batch_size=32,\n",
    "                 dim=16000, n_classes =36 ):\n",
    "        super(DataGenerator).__init__()\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_classes = n_classes\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples'\n",
    "        X = np.empty((self.batch_size, self.dim))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            curX = np.load(ID)\n",
    "            if curX.shape[0] == self.dim:\n",
    "                X[i] = curX\n",
    "            elif curX.shape[0] > self.dim:  # bigger\n",
    "                randPos = np.random.randint(curX.shape[0]-self.dim)\n",
    "                X[i] = curX[randPos:randPos+self.dim]\n",
    "            else:  # smaller\n",
    "                randPos = np.random.randint(self.dim-curX.shape[0])\n",
    "                X[i, randPos:randPos + curX.shape[0]] = curX\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGen = DataGenerator(gscInfo['train']['files'], gscInfo['train']['labels'])\n",
    "valGen   = DataGenerator(gscInfo['val']['files'], gscInfo['val']['labels'])\n",
    "testGen  = DataGenerator(gscInfo['test']['files'], gscInfo['test']['labels'], batch_size=len(gscInfo['test']['files']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\limhu\\anaconda3\\envs\\myenv\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(20,9))\n",
    "sns.countplot(pd.Series(list(y_train.values())).sort_values().map(labels) )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_waveplot(data, sr=16000):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.title(f'Waveplot for audio', size=15)\n",
    "    dispwav.waveshow(data, sr=sr)\n",
    "    plt.show()\n",
    "\n",
    "def create_spectrogram(data, sr=16000):\n",
    "    X = librosa.stft(data)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.title('Spectrogram for audio', size=15)\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')   \n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_waveplot(X_train_load[randn])\n",
    "# create_spectrogram(X_train_load[randn])\n",
    "# display(Audio(X_train_load[randn], rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train, y_test, y_val = to_categorical(list(y_train.values())), to_categorical(list(y_test.values())), to_categorical(list(y_val.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argmax(y_train, axis=1)\n",
    "# To get back target labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential()\n",
    "# model.add(Input((16000,))\n",
    "# model.add()\n",
    "# model.add(tf.keras.layers.Dense(2048, activation='leaky_relu'))\n",
    "\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(tf.keras.layers.Dense(32, activation='softmax'))\n",
    "\n",
    "def baseline(IL = 16000, categories = nCategs):\n",
    "    inputs = Input((IL,))\n",
    "    x = Normalization()(inputs)\n",
    "    x = Reshape((1,-1))(inputs)\n",
    "    x = Melspectrogram(n_dft=1024, n_hop=128, input_shape=(1, 16000),\n",
    "                       padding='same', sr=16000, n_mels=80,\n",
    "                       fmin=40.0, fmax=16000 / 2, power_melgram=1.0,\n",
    "                       return_decibel_melgram=True, trainable_fb=False,\n",
    "                       trainable_kernel=False,\n",
    "                       name='mel_stft')(x)\n",
    "    x = Dense(64, activation = 'leaky_relu')(x)\n",
    "    outputs = Dense(categories, activation = 'softmax')(x)\n",
    "    model = Model(inputs = [inputs], outputs= [outputs])\n",
    "    return model\n",
    "iters = len(X_train)/128\n",
    "LR = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "    0.001,\n",
    "    iters * 10 \n",
    ")\n",
    "\n",
    "# model = baseline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Baseline(nCategories=36, samplingrate=16000, inputLength=16000):\n",
    "#     inputs = L.Input((inputLength,))\n",
    "#     # x = Normalization()(inputs)\n",
    "\n",
    "#     x = L.Reshape((1, -1))(inputs)\n",
    "\n",
    "#     x = Melspectrogram(input_shape=(1, inputLength))(x)\n",
    "\n",
    "#     x = Normalization2D(int_axis=0)(x)\n",
    "\n",
    "#     c1 = L.Conv2D(20, (5, 1), activation='relu', padding='same')(x)\n",
    "#     c1 = L.BatchNormalization()(c1)\n",
    "#     p1 = L.MaxPooling2D((2, 1))(c1)\n",
    "#     p1 = L.Dropout(0.2)(p1)\n",
    "\n",
    "#     c2 = L.Conv2D(40, (3, 3), activation='relu', padding='same')(p1)\n",
    "#     c2 = L.BatchNormalization()(c2)\n",
    "#     p2 = L.MaxPooling2D((2, 2))(c2)\n",
    "#     p2 = L.Dropout(0.2)(p2)\n",
    "\n",
    "#     p3 = L.Flatten()(p2)\n",
    "#     p3 = L.Dense(64, activation='relu')(p3)\n",
    "#     p3 = L.Dense(32, activation='relu')(p3)\n",
    "\n",
    "#     output = L.Dense(nCategories, activation='softmax')(p3)\n",
    "\n",
    "#     model = Model(inputs=[inputs], outputs=[output], name='ConvSpeechModel')\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Baseline()\n",
    "# # model.summary()\n",
    "# model.compile(loss = ['categorical_crossentropy'], optimizer=Adam(learning_rate=LR), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = model.fit(trainGen, validation_data=valGen, epochs=2, callbacks=[EarlyStopping(monitor='categorical_accuracy', verbose=1, patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BasicLSTM(nCategories=36, InputLength=None):\n",
    "\n",
    "    inputs = L.Input((InputLength,), name='input')\n",
    "\n",
    "    x = L.Reshape((1, -1))(inputs)\n",
    "\n",
    "    m = Melspectrogram(input_shape=(1, InputLength), trainable=False)(x)\n",
    "\n",
    "    x = Normalization2D(int_axis=0, name='mel_stft_norm')(m)\n",
    "\n",
    "    x = L.Permute((2, 1, 3))(x)\n",
    "\n",
    "    x = L.Conv2D(10, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv2D(1, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "\n",
    "    x = L.Lambda(lambda q: K.squeeze(q, -1), name='squeeze_last_dim')(x)\n",
    "\n",
    "    x = L.Bidirectional(L.LSTM(64, return_sequences=True)\n",
    "                        )(x)  # [b_s, seq_len, vec_dim]\n",
    "    x = L.Bidirectional(L.LSTM(64, return_sequences=True)\n",
    "                        )(x)  # [b_s, seq_len, vec_dim]\n",
    "\n",
    "    xFirst = L.Lambda(lambda q: q[:, -1])(x)  # [b_s, vec_dim]\n",
    "    query = L.Dense(128)(xFirst)\n",
    "\n",
    "    # dot product attention\n",
    "    attScores = L.Dot(axes=[1, 2])([query, x])\n",
    "    attScores = L.Softmax(name='attSoftmax')(attScores)  # [b_s, seq_len]\n",
    "\n",
    "    # rescale sequence\n",
    "    attVector = L.Dot(axes=[1, 1])([attScores, x])  # [b_s, vec_dim]\n",
    "\n",
    "    x = L.Dense(64, activation='relu')(attVector)\n",
    "    x = L.Dense(32)(x)\n",
    "\n",
    "    output = L.Dense(nCategories, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = BasicLSTM()\n",
    "# rnn.summary()\n",
    "rnn.compile(optimizer='adam', loss=['sparse_categorical_crossentropy'], metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  21/2651 [..............................] - ETA: 32:44 - loss: 3.4799 - sparse_categorical_accuracy: 0.0744"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\limhu\\Desktop\\DL\\RNN_1.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/limhu/Desktop/DL/RNN_1.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results \u001b[39m=\u001b[39m rnn\u001b[39m.\u001b[39;49mfit(trainGen, validation_data\u001b[39m=\u001b[39;49mvalGen, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[EarlyStopping(monitor\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msparse_categorical_accuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, patience\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)])\n",
      "File \u001b[1;32mc:\\Users\\limhu\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\limhu\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\limhu\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\limhu\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\limhu\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\limhu\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\limhu\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\limhu\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\limhu\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = rnn.fit(trainGen, validation_data=valGen, epochs=20, callbacks=[EarlyStopping(monitor='sparse_categorical_accuracy', verbose=1, patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadmod = tf.keras.models.load_model('RNN/soundlstm/' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35]),\n",
       " array([   6, 3170, 3228, 3130, 2948, 3134, 3037, 3019, 3086, 2970, 3111,\n",
       "        3106, 3250, 3140, 3111, 2966, 2955, 3240, 3088, 3205, 3033, 1346,\n",
       "        1594, 1697, 1657, 1711, 1275, 1256, 1632, 1727, 1286, 1710, 1606,\n",
       "        1407, 1288, 1724], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(list(gscInfo['train']['labels'].values()), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios, labels = trainGen.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "predi = loadmod.predict(np.load('file.npy').reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unknown': 0,\n",
       " 'silence': 0,\n",
       " '_unknown_': 0,\n",
       " '_silence_': 0,\n",
       " '_background_noise_': 0,\n",
       " 'yes': 2,\n",
       " 'no': 3,\n",
       " 'up': 4,\n",
       " 'down': 5,\n",
       " 'left': 6,\n",
       " 'right': 7,\n",
       " 'on': 8,\n",
       " 'off': 9,\n",
       " 'stop': 10,\n",
       " 'go': 11,\n",
       " 'zero': 12,\n",
       " 'one': 13,\n",
       " 'two': 14,\n",
       " 'three': 15,\n",
       " 'four': 16,\n",
       " 'five': 17,\n",
       " 'six': 18,\n",
       " 'seven': 19,\n",
       " 'eight': 20,\n",
       " 'nine': 1,\n",
       " 'backward': 21,\n",
       " 'bed': 22,\n",
       " 'bird': 23,\n",
       " 'cat': 24,\n",
       " 'dog': 25,\n",
       " 'follow': 26,\n",
       " 'forward': 27,\n",
       " 'happy': 28,\n",
       " 'house': 29,\n",
       " 'learn': 30,\n",
       " 'marvin': 31,\n",
       " 'sheila': 32,\n",
       " 'tree': 33,\n",
       " 'visual': 34,\n",
       " 'wow': 35}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_noise(data, factor=0.03):\n",
    "#     noise_amp = factor*np.random.uniform()*np.amax(data)\n",
    "#     data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stretch(data, rate=0.8):\n",
    "#     return librosa.effects.time_stretch(data, rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1bc9cbc12cebf9f4e5fd05701a49f7602a29f6af4b3b1f2087f7d0e3c64a5fdf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
